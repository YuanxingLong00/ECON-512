
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Lecture 6 - Optimization</title><meta name="generator" content="MATLAB 9.4"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2018-10-03"><meta name="DC.source" content="optim.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Lecture 6 - Optimization</h1><!--introduction--><p>Optimization methods work to compute the solution to problems of the form of:</p><p><img src="optim_eq15061873740040550029.png" alt="$$ \max_{x \in X} f(x) $$" style="width:43px;height:16px;"></p><p>By finding <img src="optim_eq08097522164358817053.png" alt="$x^*$" style="width:10px;height:8px;"> the (a?) value that attains the maximum (assuming it exists).</p><p>We find these problems all over economics:</p><div><ul><li>Maximizing utility to derive demand.</li><li>Supply side decisions to maximize profits.</li><li>Cost minimization, <img src="optim_eq12828568542092297000.png" alt="$f(x) = -c(x)$" style="width:63px;height:11px;">.</li><li>Maximum likelihood estimation.</li><li>Least squares estimation.</li><li>Generalized Method of Moments.</li></ul></div><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Grid Search</a></li><li><a href="#5">Golden-Search (aka Bracketing) Method</a></li><li><a href="#11">Nelder-Mead (aka Simplex or Polytope) Method</a></li><li><a href="#13">Newton - Raphson Algorithm</a></li></ul></div><h2 id="1">Grid Search</h2><p>If <img src="optim_eq12362013959998143435.png" alt="$X$" style="width:10px;height:8px;"> contains a finite number of elemets, we could simply try all of the possible values of <img src="optim_eq12362013959998143435.png" alt="$X$" style="width:10px;height:8px;"> and choose the maximum</p><div><ul><li>Guarenteed to find the maximum.</li><li>But may be very computationally expensive.</li></ul></div><p>For example, Jia (2008, <i>Econometrica</i>) considers how Wal-Mart choses to set up a network of stores in 2065 US Counties (assuming entry is putting at least one store in a county).</p><div><ul><li>This is a finite set of options: <img src="optim_eq03873223125536733938.png" alt="$\{0,1\}$" style="width:26px;height:11px;"> for each county.</li><li>But that is <img src="optim_eq04040653578946339542.png" alt="$2^{2065} \approx 10^{600}$" style="width:58px;height:10px;"> different options.</li><li>Jia uses the structure of the model to eliminate the vast majority of   these options, but must do grid search to finish the optimization.</li></ul></div><p>If <img src="optim_eq12362013959998143435.png" alt="$X$" style="width:10px;height:8px;"> is not finite, we can approximate it with a finite set and still do a grid search.</p><div><ul><li>Suppose <img src="optim_eq12362013959998143435.png" alt="$X$" style="width:10px;height:8px;"> is <img src="optim_eq01259287712589338854.png" alt="$[0,1]^2$" style="width:25px;height:12px;">, we can do a grid search on</li></ul></div><pre class="codeinput">[X1 X2] = ndgrid(0:.2:1, 0:.2:1)
<span class="comment">%</span>
</pre><pre class="codeoutput">
X1 =

         0         0         0         0         0         0
    0.2000    0.2000    0.2000    0.2000    0.2000    0.2000
    0.4000    0.4000    0.4000    0.4000    0.4000    0.4000
    0.6000    0.6000    0.6000    0.6000    0.6000    0.6000
    0.8000    0.8000    0.8000    0.8000    0.8000    0.8000
    1.0000    1.0000    1.0000    1.0000    1.0000    1.0000


X2 =

         0    0.2000    0.4000    0.6000    0.8000    1.0000
         0    0.2000    0.4000    0.6000    0.8000    1.0000
         0    0.2000    0.4000    0.6000    0.8000    1.0000
         0    0.2000    0.4000    0.6000    0.8000    1.0000
         0    0.2000    0.4000    0.6000    0.8000    1.0000
         0    0.2000    0.4000    0.6000    0.8000    1.0000

</pre><p>Then we can approximate the maximum of <img src="optim_eq07664127158503296286.png" alt="$- (x_1-.45)^2 - (x_2+.55)^2$" style="width:123px;height:12px;">:</p><pre class="codeinput">Y = - (X1-.45).^2 - (X2-.55).^2

[val, idx] = max(Y(:))

[X1(idx) X2(idx)]
</pre><pre class="codeoutput">
Y =

   -0.5050   -0.3250   -0.2250   -0.2050   -0.2650   -0.4050
   -0.3650   -0.1850   -0.0850   -0.0650   -0.1250   -0.2650
   -0.3050   -0.1250   -0.0250   -0.0050   -0.0650   -0.2050
   -0.3250   -0.1450   -0.0450   -0.0250   -0.0850   -0.2250
   -0.4250   -0.2450   -0.1450   -0.1250   -0.1850   -0.3250
   -0.6050   -0.4250   -0.3250   -0.3050   -0.3650   -0.5050


val =

   -0.0050


idx =

    21


ans =

    0.4000    0.6000

</pre><p>While grid search is primitive, and rarely where we'd want to stop in approximating an optimum. It's often a good place to start to make sure you understand how your function behaves.</p><p>And of course, once you do one you may as well plot it (given dimensions):</p><pre class="codeinput">surf(X1, X2, Y)
</pre><img vspace="5" hspace="5" src="optim_01.png" alt=""> <p>This also gives us a chance to ilustrate the curse of dimensionality. While it is usually feasible for 2 or 3 dimensions, constructing a "reasonably dense" grid becomes impractical as the number of dimensions go up (consider Jia, above).</p><h2 id="5">Golden-Search (aka Bracketing) Method</h2><p>Assume we have a continuous, univariate function <img src="optim_eq08238684485259328926.png" alt="$f : R \rightarrow R$" style="width:50px;height:10px;">. We wish to solve:</p><p><img src="optim_eq11339644214801539111.png" alt="$$ \max_{x \in [a,b]} f(x) $$" style="width:46px;height:18px;"></p><p>Bracketing suggests:</p><div><ol><li>Picking two points <img src="optim_eq08754735650462632936.png" alt="$x_1 < x_2$" style="width:35px;height:8px;"> in the interior of <img src="optim_eq13883490000178595005.png" alt="$[a, b]$" style="width:19px;height:11px;"> to compute the funciton.</li><li>If <img src="optim_eq02494616210028101484.png" alt="$b-a < \epsilon$" style="width:43px;height:9px;">, then the bracket is small and return the maximum of <img src="optim_eq18205750245975743710.png" alt="$\{f(a), f(x_1), f(x_2), f(b)\}$" style="width:117px;height:11px;">.</li><li>If <img src="optim_eq16698428455072204573.png" alt="$f(x_1) &gt; f(x_2)$" style="width:65px;height:11px;">, we know a local maximum must be inside <img src="optim_eq02448223187117853017.png" alt="$[a, x_2]$" style="width:25px;height:11px;">, so set <img src="optim_eq13368255149514558658.png" alt="$b = x_2$" style="width:29px;height:10px;"> and go to 1.</li><li>If <img src="optim_eq04755883228010882153.png" alt="$f(x_1) < f(x_2)$" style="width:65px;height:11px;">, we know a local maximum must be inside <img src="optim_eq10273086320064402578.png" alt="$[x_1, b]$" style="width:24px;height:11px;">, so set <img src="optim_eq13977831142289001673.png" alt="$a = x_2$" style="width:30px;height:7px;"> and go to 1.</li></ol></div><p>The only question is how to pick the interior points. They can be uniquely determined by two criteria:</p><div><ul><li>In successive iterations, be able to "re-use" the previous function evalutation so the algorithm only chooses one new point.</li><li>The length of the new interval is independent of which sub-interval is chosen.</li></ul></div><p>These conditions lead to:</p><p><img src="optim_eq02880038282425867836.png" alt="$$x_i = a + \alpha_i(b - a), $$ where&#xA;$$ \alpha_1 = \frac{3 - \sqrt{5}}{2} $$ and&#xA;$$ \alpha_2 = \frac{\sqrt{5} - 1}{2}. $$" style="width:277px;height:25px;"></p><p>The value for <img src="optim_eq03151659423380361585.png" alt="$\alpha_2$" style="width:11px;height:7px;"> is the <a href="https://en.wikipedia.org/wiki/Golden_ratio">``Golden Ratio''</a> from Euclid.</p><p>Let's use this method to find the maximum of our old friend:</p><pre class="codeinput">X = -2:.1:4;
f = @(x) 2 + exp(x) - 3.*(x.^2);
plot(X, f(X), X, zeros(size(X)));
</pre><img vspace="5" hspace="5" src="optim_02.png" alt=""> <p>Miranda and Fackler have a simple implementation of golden search, so let's add their library:</p><pre class="codeinput">addpath(<span class="string">'../CEtools/'</span>);
</pre><pre class="codeoutput">Warning: Name is nonexistent or not a directory:
/Users/macbook/Documents/GitHub/ECON-512/CEtools 
</pre><p>Their function is <tt>golden</tt>:</p><pre class="error">File '../CEtools/golden.m' not found.</pre><p>So we just call:</p><pre class="codeinput">[xmax, fmax] = golden(f, -2, 4)
</pre><pre class="codeoutput error">Undefined function 'golden' for input arguments of type 'function_handle'.

Error in optim (line 115)
[xmax, fmax] = golden(f, -2, 4)
</pre><div><ul><li>Did we find the find the maximum in <img src="optim_eq15939784087677158776.png" alt="$[-2, 4]$" style="width:28px;height:11px;">? No. The maximum is</li></ul></div><pre class="codeinput">f(4)
</pre><div><ul><li>Did the algorithm ``work''? Yes.</li><li>Golden search, like most of the algorithms we consider, will find a <b>local</b> maximum. This is another reason doing some grid searches is often advisable.</li></ul></div><h2 id="11">Nelder-Mead (aka Simplex or Polytope) Method</h2><p>So how to search for a maximum in a multi-dimensionsal space? The most common derivative free method is the Nelder-Mead alogorithm. Its intuition is straightforward. Define a simplex of points (<img src="optim_eq07159614207615147805.png" alt="$N+1$" style="width:28px;height:9px;">) for an <img src="optim_eq03672095713503266041.png" alt="$N$" style="width:10px;height:8px;"> dimensional space. Take the lowest (worst) point and reflect it across the hyperplane of the remaining points. The hope is the new point will be better than the second lowest point and your simplex will "climb" the hill.</p><p>The algorithm is more illustrative. This one is adapted from Judd:</p><p>For an <img src="optim_eq03672095713503266041.png" alt="$N$" style="width:10px;height:8px;"> dimensional funciton, initialize <img src="optim_eq02316762589684127914.png" alt="$\{x^1, \ldots, x^{N+1} \}$" style="width:69px;height:13px;"> as the starting simplex.</p><div><ol><li>Sort the verticies such that <img src="optim_eq13547660217806084995.png" alt="$f(x^1) \leq f(x^2) \leq \cdots \leq f(x^{N+1})$" style="width:146px;height:13px;">.</li><li>Find the lowest <img src="optim_eq05671228016298599287.png" alt="$i$" style="width:3px;height:8px;"> such that reflecting <img src="optim_eq12820131146281424892.png" alt="$x^i$" style="width:9px;height:10px;"> across the remaining points produces a point <img src="optim_eq16066156376842473745.png" alt="$r^i$" style="width:8px;height:10px;"> such that <img src="optim_eq07771251289555853009.png" alt="$f(x^i) < f(y^i)$" style="width:62px;height:12px;">. Set <img src="optim_eq00228820217283711085.png" alt="$x^i \leftarrow y^i$" style="width:35px;height:12px;">, go to 1. If no such point exists, continue to 3.</li><li>If the area of the current simplex is less than <img src="optim_eq04934585835479885722.png" alt="$\varepsilon$" style="width:5px;height:6px;">, Return <img src="optim_eq15868515817472399823.png" alt="$f(x^{N+1})$" style="width:38px;height:13px;">. Otherwise, go to 4.</li><li>Shrink the simlex towards the best point, set <img src="optim_eq14996664558200760115.png" alt="$x^i \leftarrow \frac{1}{2}(x^i + x^{N+1})$" style="width:87px;height:14px;">, go to step 1.</li></ol></div><p>To calculate a reflection:</p><p><img src="optim_eq06835050449751263888.png" alt="$$ r_i = x_i + 2 \left( \frac{1}{n} \sum_{j\neq i} x_j - x_i \right) $$" style="width:132px;height:40px;"></p><p>This algorithm will converge to a local min (for small enough tolerance), but can be very slow. It is often useful to include expansion steps so your simplex doesn't shrink pre-maturely.</p><p>MATLAB's native implementation of Nealder-Mead is <tt>fminsearch</tt>, the full algorithm for this implementaiton is described <a href="https://www.mathworks.com/help/matlab/math/optimizing-nonlinear-functions.html#bsgpq6p-11">here</a>.</p><p>Note that MATLAB's fminsearch <b>minimizes</b> <img src="optim_eq17663307419741296505.png" alt="$f(x)$" style="width:20px;height:11px;">, this is the typical convention from engineering.</p><pre class="codeinput">options = optimset(<span class="string">'PlotFcns'</span>,@optimplotfval, <span class="string">'Display'</span>,<span class="string">'iter'</span>);
fun = @(x)100*(x(2) - x(1)^2)^2 + (1 - x(1))^2;
x0 = [-1.2,1];
x = fminsearch(fun,x0,options)
</pre><p>FYI, There is also an implementation of Nelder-Mead in CETools, <tt>neldmead.m</tt>. I don't know of anyone who has used it on research code.</p><p>When to use Nelder-Mead:</p><div><ol><li>Derivative information is hard to compute.</li><li>Funciton is very rough, so local derivative information is noisy.</li><li>You have some discontinuities.</li></ol></div><p>The original Berry, Levinsohn, and Pakes (1995) code (which we'll look at in a couple weeks) used the Nelder-Mead algorithm, although it may not be the best choice for this sort of problem today.</p><h2 id="13">Newton - Raphson Algorithm</h2><p>Newton's method for solving a root finding problem was successive linearization. Newton's method for optimization is to use successive <b>quadratic</b> approximations.</p><p>Given <img src="optim_eq01769579049475718566.png" alt="$x^{(k)}$" style="width:16px;height:11px;"> use a second-order Taylor approximation of <img src="optim_eq01396220931821195467.png" alt="$f: R^N \rightarrow R$" style="width:57px;height:12px;"> around  <img src="optim_eq01769579049475718566.png" alt="$x^{(k)}$" style="width:16px;height:11px;">:</p><p><img src="optim_eq10919913171538049804.png" alt="$$f(x) \approx f(x^{(k)}) + f'(x^{(k)}) (x - x^{(k)}) + \frac{1}{2}(x - x^{(k)})^T f''(x^{(k)})(x -x^{(k)}) $$" style="width:316px;height:23px;"></p><p>The approximate problem has <img src="optim_eq03672095713503266041.png" alt="$N$" style="width:10px;height:8px;"> first order condtions:</p><p><img src="optim_eq17398896970582918914.png" alt="$$  f'(x^{(k)}) + f''(x^{(k)}) (x - x^{(k)}) = 0 $$" style="width:151px;height:14px;"></p><p>Which leads to an iteration rule,</p><p><img src="optim_eq01050611610791737092.png" alt="$$ x^{(k+1)} \leftarrow x^{(k)} - [f''(x^{(k)})]^{-1} f'(x^{(k)}) $$" style="width:162px;height:14px;"></p><p>Note that this is the same iteration rule we would use if we applied Newton's method as a rootfinder of the first order conditions. All of the caveats we mentioned during rootfinding still apply:</p><div><ul><li>Guarenteed to converge if initial <img src="optim_eq12428413953531653171.png" alt="$x$" style="width:6px;height:6px;"> is ``sufficiently close'' but no test for how close this must be.</li><li>Additional complexity to compute gradient and Hessian. Hessian now is <img src="optim_eq17485149629088528067.png" alt="$O(N^2)$" style="width:30px;height:12px;"> to store and <img src="optim_eq17658951522823245838.png" alt="$O(N^3)$" style="width:30px;height:12px;"> to compute.</li><li>Inversion step should really be accomplisted by solving a linear equation.</li><li>No guarentee that Hessian is postitive (max) or negative (min) definite, if it is not, a newton iteration could take a step "backward".</li><li>If it converges, we only know the converged point is a local minimum. (In fact, we'll use solving the first order conditions as the stopping rule.)</li></ul></div><p>Let's do a quick example where we want to minimize,</p><p><img src="optim_eq07450981496122028925.png" alt="$$f(x)=(x_1-x_2)^4+2x_1^2+x_2^2-x_1+2x_2$$" style="width:190px;height:13px;"></p><p>The Gradient is, (swtiching to Judd's notation so you see both).</p><p><img src="optim_eq05494881929474775986.png" alt="$$\nabla f(x) = \left( \begin{array}{c} 4(x_1-x_2)^3+4x_1-1 \\ -4(x_1-x_2)^3+2x_2+2  \end{array} \right) $$" style="width:181px;height:27px;"></p><p>The Hessian is,</p><p><img src="optim_eq05286064161493294139.png" alt="$$ H(x) = \left( \begin{array}{cc} 12(x_1 - x_2)^2 + 4 &amp; -12(x_1 - x_2)^2 \\  -12(x_1 - x_2)^2 &amp; 12(x_1 - x_2)^2 + 2 \end{array} \right) $$" style="width:231px;height:27px;"></p><p>So the Newton-Raphson Iteration rule is:</p><p><img src="optim_eq11873483641204099325.png" alt="$$ x^{(k+1)} \leftarrow x^{(k)} - [H(x^{(k)})]^{-1} \nabla f(x^{(k)}) $$" style="width:167px;height:14px;"></p><p>Implemented in MATLAB, this looks like:</p><pre class="codeinput">n=0;            <span class="comment">%initialize iteration counter</span>
focerr=1;          <span class="comment">%initialize error</span>
x=[1;1];        <span class="comment">%set starting value</span>

<span class="comment">%Computation loop</span>
<span class="keyword">while</span> focerr&gt;1e-10&amp;n&lt;100
    <span class="comment">%Compute Gradient</span>
    gradf=[4*(x(1)-x(2))^3+4*x(1)-1;<span class="keyword">...</span>
          -4*(x(1)-x(2))^3+2*x(2)+2];

    <span class="comment">%Compute Hessian</span>
    Hf=     [12*(x(1)-x(2))^2+4,  -12*(x(1)-x(2))^2;<span class="keyword">...</span>
            -12*(x(1)-x(2))^2,    12*(x(1)-x(2))^2+2];

    <span class="comment">%Perform Iteration</span>
    y=x-Hf\gradf;
    x=y;
    n=n+1;

    <span class="comment">%Calculate FOC Error</span>
    focerr= norm(gradf);

<span class="keyword">end</span>
n,x,focerr,        <span class="comment">%display end values</span>
</pre><p>Notice this really is just rootfinding for the FOCs we never even compute the objective function during the iterations.</p><pre class="codeinput">f = @(x) (x(1) - x(2))^4 + 2*x(1)^2 + x(2)^2 - x(1) + 2*x(2);
f(x)
</pre><p>We didn't even explicitly say whether we were minimizing or maximizing, just looking for a local critical point.</p><p>While it is the theoretical foundation for many derivative based optimization algorithms, Newton-Raphson itself is rarely implemented in practice.</p><div><ul><li>Computing the Hessian is costly, and approximations often work well.</li><li>Flexibility in the magnitude of the step is often beneficial.</li><li>Steepest descent methods make sure we are progressing towards a max or min, not just to a critical point.</li></ul></div><p>We'll cover these methods next week.</p><p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2018a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Lecture 6 - Optimization
%
% Optimization methods work to compute the solution to problems of the
% form of: 
%
% $$ \max_{x \in X} f(x) $$
%
% By finding $x^*$ the (a?) value that attains the maximum (assuming it
% exists). 
%
% We find these problems all over economics: 
%
% * Maximizing utility to derive demand. 
% * Supply side decisions to maximize profits. 
% * Cost minimization, $f(x) = -c(x)$. 
% * Maximum likelihood estimation. 
% * Least squares estimation. 
% * Generalized Method of Moments. 
%
%% Grid Search
%
% If $X$ contains a finite number of elemets, we could simply try all of the 
% possible values of $X$ and choose the maximum
%
% * Guarenteed to find the maximum. 
% * But may be very computationally expensive. 
%
% For example, Jia (2008, _Econometrica_) considers how Wal-Mart choses to
% set up a network of stores in 2065 US Counties (assuming entry is putting
% at least one store in a county). 
%
% * This is a finite set of options: $\{0,1\}$ for each county. 
% * But that is $2^{2065} \approx 10^{600}$ different options. 
% * Jia uses the structure of the model to eliminate the vast majority of
%   these options, but must do grid search to finish the optimization. 
%
% If $X$ is not finite, we can approximate it with a finite set and still
% do a grid search. 
%
% * Suppose $X$ is $[0,1]^2$, we can do a grid search on 
[X1 X2] = ndgrid(0:.2:1, 0:.2:1)
%
%% 
% Then we can approximate the maximum of $- (x_1-.45)^2 - (x_2+.55)^2$: 
Y = - (X1-.45).^2 - (X2-.55).^2 

[val, idx] = max(Y(:))

[X1(idx) X2(idx)]
%%
% While grid search is primitive, and rarely where we'd want to stop in
% approximating an optimum. It's often a good place to start to make sure
% you understand how your function behaves. 
%
% And of course, once you do one you may as well plot it (given dimensions): 
surf(X1, X2, Y)

%% 
% This also gives us a chance to ilustrate the curse of dimensionality. While
% it is usually feasible for 2 or 3 dimensions, constructing a "reasonably
% dense" grid becomes impractical as the number of dimensions go up
% (consider Jia, above). 

%% Golden-Search (aka Bracketing) Method
%
% Assume we have a continuous, univariate function $f : R \rightarrow R$.
% We wish to solve: 
%
% $$ \max_{x \in [a,b]} f(x) $$
%
% Bracketing suggests: 
%
% # Picking two points $x_1 < x_2$ in the interior of $[a, b]$ to compute the
% funciton. 
% # If $b-a < \epsilon$, then the bracket is small and return the maximum
% of $\{f(a), f(x_1), f(x_2), f(b)\}$.
% # If $f(x_1) > f(x_2)$, we know a local maximum must be inside $[a, x_2]$,
% so set $b = x_2$ and go to 1.
% # If $f(x_1) < f(x_2)$, we know a local maximum must be inside $[x_1, b]$,
% so set $a = x_2$ and go to 1.
%
% The only question is how to pick the interior points. They can be
% uniquely determined by two criteria: 
%
% * In successive iterations, be able to "re-use" the previous function
% evalutation so the algorithm only chooses one new point. 
% * The length of the new interval is independent of which sub-interval is
% chosen. 
%
% These conditions lead to: 
%
% $$x_i = a + \alpha_i(b - a), $$ where
% $$ \alpha_1 = \frac{3 - \sqrt{5}}{2} $$ and
% $$ \alpha_2 = \frac{\sqrt{5} - 1}{2}. $$
%
% The value for $\alpha_2$ is the <https://en.wikipedia.org/wiki/Golden_ratio ``Golden Ratio''> from Euclid. 
%
% Let's use this method to find the maximum of our old friend: 
X = -2:.1:4;
f = @(x) 2 + exp(x) - 3.*(x.^2);
plot(X, f(X), X, zeros(size(X)));

%% 
% Miranda and Fackler have a simple implementation of golden search, so
% let's add their library: 
addpath('../CEtools/');

%%
% Their function is |golden|:
%
% <include>../CEtools/golden.m</include>
%
%%
% So we just call: 
[xmax, fmax] = golden(f, -2, 4)
%%
% * Did we find the find the maximum in $[-2, 4]$? No. The maximum is 
f(4)
%%
% * Did the algorithm ``work''? Yes. 
% * Golden search, like most of the algorithms we consider, will find a
% *local* maximum. This is another reason doing some grid searches is
% often advisable. 
%% Nelder-Mead (aka Simplex or Polytope) Method
%
% So how to search for a maximum in a multi-dimensionsal space? The most
% common derivative free method is the Nelder-Mead alogorithm. Its
% intuition is straightforward. Define a simplex of points ($N+1$) for an $N$
% dimensional space. Take the lowest (worst) point and reflect it across
% the hyperplane of the remaining points. The hope is the new point will be
% better than the second lowest point and your simplex will "climb" the
% hill. 
%
% The algorithm is more illustrative. This one is adapted from Judd: 
%
% For an $N$ dimensional funciton, initialize $\{x^1, \ldots, x^{N+1} \}$
% as the starting simplex. 
% 
% # Sort the verticies such that $f(x^1) \leq f(x^2) \leq \cdots \leq
% f(x^{N+1})$. 
% # Find the lowest $i$ such that reflecting $x^i$ across the remaining
% points produces a point $r^i$ such that $f(x^i) < f(y^i)$. Set $x^i \leftarrow y^i$,
% go to 1. If no such point exists, continue to 3. 
% # If the area of the current simplex is less than $\varepsilon$, Return $f(x^{N+1})$.
% Otherwise, go to 4. 
% # Shrink the simlex towards the best point, set $x^i \leftarrow
% \frac{1}{2}(x^i + x^{N+1})$, go to step 1. 
%
% To calculate a reflection: 
%
% $$ r_i = x_i + 2 \left( \frac{1}{n} \sum_{j\neq i} x_j - x_i \right) $$
%
%
% This algorithm will converge to a local min (for small enough tolerance), but can be very slow. It is
% often useful to include expansion steps so your simplex doesn't shrink
% pre-maturely. 
%
% MATLAB's native implementation of Nealder-Mead is |fminsearch|, the full algorithm for this implementaiton is
% described
% <https://www.mathworks.com/help/matlab/math/optimizing-nonlinear-functions.html#bsgpq6p-11 here>.
%
% Note that MATLAB's fminsearch *minimizes* $f(x)$, this is the typical
% convention from engineering. 
options = optimset('PlotFcns',@optimplotfval, 'Display','iter');
fun = @(x)100*(x(2) - x(1)^2)^2 + (1 - x(1))^2;
x0 = [-1.2,1];
x = fminsearch(fun,x0,options)
%%
% FYI, There is also an implementation of Nelder-Mead in CETools,
% |neldmead.m|. I don't know of anyone who has used it on research code. 
%
% When to use Nelder-Mead: 
%
% # Derivative information is hard to compute. 
% # Funciton is very rough, so local derivative information is noisy. 
% # You have some discontinuities. 
%
% The original Berry, Levinsohn, and Pakes (1995) code (which we'll look at in a couple weeks) used the Nelder-Mead algorithm,
% although it may not be the best choice for this sort of problem today.

%% Newton - Raphson Algorithm 
%
% Newton's method for solving a root finding problem was successive
% linearization. Newton's method for optimization is to use successive
% *quadratic* approximations. 
%
% Given $x^{(k)}$ use a second-order Taylor approximation of $f: R^N \rightarrow R$
% around  $x^{(k)}$:
%
% $$f(x) \approx f(x^{(k)}) + f'(x^{(k)}) (x - x^{(k)}) + \frac{1}{2}(x - x^{(k)})^T f''(x^{(k)})(x -x^{(k)}) $$
%
% The approximate problem has $N$ first order condtions: 
%
% $$  f'(x^{(k)}) + f''(x^{(k)}) (x - x^{(k)}) = 0 $$
%
% Which leads to an iteration rule, 
%
% $$ x^{(k+1)} \leftarrow x^{(k)} - [f''(x^{(k)})]^{-1} f'(x^{(k)}) $$
%
% Note that this is the same iteration rule we would use if we applied
% Newton's method as a rootfinder of the first order conditions. All of the
% caveats we mentioned during rootfinding still apply: 
%
% * Guarenteed to converge if initial $x$ is ``sufficiently close'' but no
% test for how close this must be. 
% * Additional complexity to compute gradient and Hessian. Hessian now is
% $O(N^2)$ to store and $O(N^3)$ to compute.
% * Inversion step should really be accomplisted by solving a linear
% equation. 
% * No guarentee that Hessian is postitive (max) or negative (min) definite, if it is not, a newton
% iteration could take a step "backward". 
% * If it converges, we only know the converged point is a local minimum.
% (In fact, we'll use solving the first order conditions as the stopping
% rule.)

%% 
% Let's do a quick example where we want to minimize, 
%
% $$f(x)=(x_1-x_2)^4+2x_1^2+x_2^2-x_1+2x_2$$
%
% The Gradient is, (swtiching to Judd's notation so you see both).  
%
% $$\nabla f(x) = \left( \begin{array}{c} 4(x_1-x_2)^3+4x_1-1 \\ -4(x_1-x_2)^3+2x_2+2  \end{array} \right) $$
%
% The Hessian is, 
%
% $$ H(x) = \left( \begin{array}{cc} 12(x_1 - x_2)^2 + 4 & -12(x_1 - x_2)^2 \\  -12(x_1 - x_2)^2 & 12(x_1 - x_2)^2 + 2 \end{array} \right) $$
%
% So the Newton-Raphson Iteration rule is: 
%
% $$ x^{(k+1)} \leftarrow x^{(k)} - [H(x^{(k)})]^{-1} \nabla f(x^{(k)}) $$
%
% Implemented in MATLAB, this looks like: 
n=0;            %initialize iteration counter 
focerr=1;          %initialize error 
x=[1;1];        %set starting value

%Computation loop 
while focerr>1e-10&n<100 
    %Compute Gradient
    gradf=[4*(x(1)-x(2))^3+4*x(1)-1;...
          -4*(x(1)-x(2))^3+2*x(2)+2];                            
    
    %Compute Hessian
    Hf=     [12*(x(1)-x(2))^2+4,  -12*(x(1)-x(2))^2;...           
            -12*(x(1)-x(2))^2,    12*(x(1)-x(2))^2+2]; 
    
    %Perform Iteration
    y=x-Hf\gradf; 
    x=y;                                                          
    n=n+1; 
    
    %Calculate FOC Error
    focerr= norm(gradf);                            
                                                          
end 
n,x,focerr,        %display end values



%% 
% Notice this really is just rootfinding for the FOCs we never even compute
% the objective function during the iterations.  
f = @(x) (x(1) - x(2))^4 + 2*x(1)^2 + x(2)^2 - x(1) + 2*x(2);
f(x)
%%
% We didn't even explicitly say whether we were minimizing or maximizing,
% just looking for a local critical point. 
%
% While it is the theoretical foundation for many derivative based
% optimization algorithms, Newton-Raphson itself is rarely implemented in
% practice. 
%
% * Computing the Hessian is costly, and approximations often work well. 
% * Flexibility in the magnitude of the step is often beneficial. 
% * Steepest descent methods make sure we are progressing towards a max or
% min, not just to a critical point. 
%
% We'll cover these methods next week.


##### SOURCE END #####
--></body></html>